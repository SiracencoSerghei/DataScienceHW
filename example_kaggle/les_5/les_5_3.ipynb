{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiracencoSerghei/DataScienceHW/blob/main/example_kaggle/les_5/les_5_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlXPBdYoy7D4",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "\n",
        "import scipy.io as scio\n",
        "from scipy.fftpack import fft, rfft\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from sklearn import svm, datasets, preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, classification_report, confusion_matrix, f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMHgyCHPy7D5"
      },
      "source": [
        "---\n",
        "# LOAD DATASET\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J33_c3ZGy7D5",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdDf7F7I3ml6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9izq92s1Tuew"
      },
      "outputs": [],
      "source": [
        "# !ls '/content/drive/My Drive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EbV8kIl4_mT6"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/My Drive/homework.zip' -d /content/homework  # Colab RAM\n",
        "# !unzip '/content/drive/My Drive/homework.zip' -d '/content/drive/My Drive/homework'  # my google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rrn7X4eXDlh"
      },
      "outputs": [],
      "source": [
        "base_path = '/content/homework/data'\n",
        "!ls {base_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFZs3XPiX55j"
      },
      "outputs": [],
      "source": [
        "activities = os.listdir(base_path)\n",
        "print(activities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPh4yqN5Pe5-"
      },
      "outputs": [],
      "source": [
        "\n",
        "for act in activities:\n",
        "    path = os.path.join(base_path, act)\n",
        "\n",
        "    if os.path.isdir(path):  # Переконуємося, що path є папкою\n",
        "        frames = os.listdir(path)\n",
        "        print(f'Folder \"{act}\" has: {len(frames)} files')\n",
        "    else:\n",
        "        print(f'Warning: \"{act}\" is not a valid directory!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Z7IC9b6YtpF"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Вказуємо шлях до каталогу з даними\n",
        "folder = Path(base_path)\n",
        "data_set = pd.DataFrame()\n",
        "\n",
        "# Проходимо по всіх підкаталогах\n",
        "for activity_folder in folder.iterdir():\n",
        "    if not activity_folder.is_dir():\n",
        "        continue\n",
        "\n",
        "    # Проходимо по всіх файлах в підкаталозі\n",
        "    for file in activity_folder.iterdir():\n",
        "        if file.suffix != '.csv':\n",
        "            continue\n",
        "\n",
        "        # Читаємо CSV файл і додаємо стовпець activity\n",
        "        df = pd.read_csv(file)\n",
        "        df['activity'] = activity_folder.name\n",
        "        data_set = pd.concat([data_set, df], ignore_index=True)\n",
        "\n",
        "data_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axiU7AKHUW-S"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_stat_features(frame):\n",
        "    # Видаляємо текстовий стовпець \"activity\", залишаємо тільки числові дані\n",
        "    frame = frame.drop(columns=['activity'])\n",
        "\n",
        "    # Обчислення статистичних фіч\n",
        "    skewness = frame.skew(axis=0).values\n",
        "    kurtosis = frame.kurt(axis=0).values\n",
        "    maximum = frame.max(axis=0).values\n",
        "    minimum = frame.min(axis=0).values\n",
        "    mean = frame.mean(axis=0).values\n",
        "    stddev = frame.std(axis=0).values\n",
        "    variance = frame.var(axis=0).values\n",
        "    median = frame.median(axis=0).values\n",
        "    idxmax = frame.idxmax(axis=0).values\n",
        "    idxmin = frame.idxmin(axis=0).values\n",
        "\n",
        "    # Список назв статистичних фіч\n",
        "    stat_feature_names = [\n",
        "        'skew_X', 'skew_Y', 'skew_Z',\n",
        "        'kurt_X', 'kurt_Y', 'kurt_Z',\n",
        "        'max_X', 'max_Y', 'max_Z',\n",
        "        'min_X', 'min_Y', 'min_Z',\n",
        "        'mean_X', 'mean_Y', 'mean_Z',\n",
        "        'std_X', 'std_Y', 'std_Z',\n",
        "        'var_X', 'var_Y', 'var_Z',\n",
        "        'median_X', 'median_Y', 'median_Z',\n",
        "        'idxmax_X', 'idxmax_Y', 'idxmax_Z',\n",
        "        'idxmin_X', 'idxmin_Y', 'idxmin_Z'\n",
        "    ]\n",
        "\n",
        "    # Об'єднуємо статистичні значення в один масив\n",
        "    features = np.concatenate([\n",
        "        skewness, kurtosis, maximum, minimum, mean, stddev, variance, median, idxmax, idxmin\n",
        "    ], axis=0)\n",
        "\n",
        "    # Обчислюємо кореляцію між акселерометрами\n",
        "    correlation = frame.corr()\n",
        "    corr_values = [\n",
        "        correlation.loc['accelerometer_X', 'accelerometer_Y'],\n",
        "        correlation.loc['accelerometer_X', 'accelerometer_Z'],\n",
        "        correlation.loc['accelerometer_Y', 'accelerometer_Z']\n",
        "    ]\n",
        "    # Додаємо назви для кореляцій\n",
        "    corr_feature_names = [\n",
        "        'corr_XY', 'corr_XZ', 'corr_YZ'\n",
        "    ]\n",
        "    features = np.concatenate((features, corr_values), axis=0)\n",
        "\n",
        "    # Обчислення MAE та RMSE\n",
        "    mean_values = frame.mean(axis=0)\n",
        "    mae_X = mean_absolute_error(frame['accelerometer_X'], np.full_like(frame['accelerometer_X'], mean_values['accelerometer_X']))\n",
        "    mae_Y = mean_absolute_error(frame['accelerometer_Y'], np.full_like(frame['accelerometer_Y'], mean_values['accelerometer_Y']))\n",
        "    mae_Z = mean_absolute_error(frame['accelerometer_Z'], np.full_like(frame['accelerometer_Z'], mean_values['accelerometer_Z']))\n",
        "\n",
        "    rmse_X = np.sqrt(mean_squared_error(frame['accelerometer_X'], np.full_like(frame['accelerometer_X'], mean_values['accelerometer_X'])))\n",
        "    rmse_Y = np.sqrt(mean_squared_error(frame['accelerometer_Y'], np.full_like(frame['accelerometer_Y'], mean_values['accelerometer_Y'])))\n",
        "    rmse_Z = np.sqrt(mean_squared_error(frame['accelerometer_Z'], np.full_like(frame['accelerometer_Z'], mean_values['accelerometer_Z'])))\n",
        "\n",
        "    metrics = np.array([mae_X, mae_Y, mae_Z, rmse_X, rmse_Y, rmse_Z])\n",
        "    # Додаємо назви для MAE та RMSE\n",
        "    metrics_feature_names = [\n",
        "        'mae_X', 'mae_Y', 'mae_Z',\n",
        "        'rmse_X', 'rmse_Y', 'rmse_Z'\n",
        "    ]\n",
        "    features = np.concatenate((features, metrics), axis=0)\n",
        "\n",
        "    # Об'єднуємо всі назви фіч\n",
        "    all_feature_names = stat_feature_names + corr_feature_names + metrics_feature_names\n",
        "\n",
        "    # Повертаємо словник з назвами та значеннями фіч\n",
        "    feature_dict = dict(zip(all_feature_names, features))\n",
        "    return feature_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PX8Ub_uvXw4o"
      },
      "outputs": [],
      "source": [
        "len(get_stat_features(data_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqFzKBNUcc78"
      },
      "outputs": [],
      "source": [
        "# get_stat_features(data_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OrI89nkbU1u"
      },
      "source": [
        "---\n",
        "# Data Preraration\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OqeiP-tba85"
      },
      "outputs": [],
      "source": [
        "data_set.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twhvEjKeJuQO"
      },
      "outputs": [],
      "source": [
        "data_set.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef-ORsJ1LBu6"
      },
      "source": [
        "---\n",
        "# Навчання моделі без часових ознак\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBdzic93ggJv"
      },
      "outputs": [],
      "source": [
        "# Функція для побудови confusion matrix\n",
        "def plot_confusion_matrix(conf_matrices, classifiers, activities, axes):\n",
        "    custom_cmap = sns.color_palette(\"ch:s=.5,r=-.75\", as_cmap=True)\n",
        "\n",
        "    for i, classifier in enumerate(classifiers):\n",
        "        sns.heatmap(\n",
        "            conf_matrices[i],\n",
        "            annot=True,\n",
        "            fmt='d',\n",
        "            cmap=custom_cmap,\n",
        "            xticklabels=activities,\n",
        "            yticklabels=activities,\n",
        "            ax=axes[i],\n",
        "        )\n",
        "\n",
        "        axes[i].set_title(f\"Confusion Matrix for {classifier} Classifier\")\n",
        "        axes[i].set_xlabel(\"Predicted activity\")\n",
        "        axes[i].set_ylabel(\"True activity\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSZLFgAULFSv"
      },
      "outputs": [],
      "source": [
        "# Основний код\n",
        "features = data_set.columns[:-1]\n",
        "X = data_set[features]\n",
        "y = data_set[data_set.columns[-1]]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "normalized_data = scaler.fit_transform(X)\n",
        "\n",
        "norm_data = data_set.copy()\n",
        "norm_data[features] = normalized_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azwYS2QEg2S1"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(norm_data[features], norm_data['activity'], test_size=0.3, stratify=norm_data['activity'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oaq6dPXfl2Ny"
      },
      "outputs": [],
      "source": [
        "np.array_equal(X, X_fft_stat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2lM3zVGktLq"
      },
      "outputs": [],
      "source": [
        "print(\"Розмір тренувальної вибірки:\", X_train.shape)\n",
        "print(\"Розмір тестової вибірки:\", X_test.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcW9E_gPg9If"
      },
      "outputs": [],
      "source": [
        "# Навчання моделей\n",
        "model_svm = SVC(decision_function_shape='ovo', kernel='rbf',gamma=0.005, probability=True)\n",
        "model_svm.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1piWEj6mfoT"
      },
      "outputs": [],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofg3ZoLMm1DP"
      },
      "outputs": [],
      "source": [
        "y_test_pred = model_svm.decision_function(X_test)\n",
        "y_test_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqeaNEWnnFC7"
      },
      "outputs": [],
      "source": [
        "y_test_proba = model_svm.predict_proba(X_test)\n",
        "y_test_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBWBf3mPnLnY"
      },
      "outputs": [],
      "source": [
        "y_test_proba = np.argmax(y_test_proba, axis=1)\n",
        "y_test_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErnOLQKEnxK3"
      },
      "outputs": [],
      "source": [
        "count_idle = 0\n",
        "count_running = 0\n",
        "count_stairs = 0\n",
        "count_walking = 0\n",
        "for i in y_test_proba:\n",
        "  if i == 0:\n",
        "    count_idle += 1\n",
        "  elif i == 1:\n",
        "    count_running += 1\n",
        "  elif i == 2:\n",
        "    count_stairs += 1\n",
        "  elif i == 3:\n",
        "    count_walking += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGo-MgtaoAEh"
      },
      "outputs": [],
      "source": [
        "count_idle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXoVFKluoEE_"
      },
      "outputs": [],
      "source": [
        "count_running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZfFc7jNoFfn"
      },
      "outputs": [],
      "source": [
        "count_stairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oil5VIvfoGl2"
      },
      "outputs": [],
      "source": [
        "count_walking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzJIoEO-oLe7"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(y_test, y_test_proba)\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rqb60dHmjN9y"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "model_rf = RandomForestClassifier(n_estimators=100)\n",
        "model_rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmN9oSqWhBMQ"
      },
      "outputs": [],
      "source": [
        "# Оцінка точності\n",
        "score_svm = model_svm.score(X_test, y_test)\n",
        "score_rf = model_rf.score(X_test, y_test)\n",
        "\n",
        "print(\"Точність моделі SVM:\", score_svm)\n",
        "print(\"Точність моделі Random Forest:\", score_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m27aBJHFhERr"
      },
      "outputs": [],
      "source": [
        "# Прогнозування\n",
        "y_pred_svm = model_svm.predict(X_test)\n",
        "y_pred_rf = model_rf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEVM9QHLhIh9"
      },
      "outputs": [],
      "source": [
        "# Обчислення confusion matrix\n",
        "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
        "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "# Візуалізація confusion matrix\n",
        "fig, axes = plt.subplots(1, 2, figsize=(11, 4))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
