{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiracencoSerghei/DataScienceHW/blob/main/example_kaggle/les_7/lightFM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "640rv3QiDsqf",
        "outputId": "d5e2aff5-c45a-4efd-dea7-4a5aad68b8db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightfm\n",
            "  Downloading lightfm-1.17.tar.gz (316 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lightfm) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from lightfm) (1.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from lightfm) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from lightfm) (1.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (2025.1.31)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->lightfm) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->lightfm) (3.5.0)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.17-cp311-cp311-linux_x86_64.whl size=831166 sha256=99590899fbc53575825b7e697d2a75d5a5ad7e719002a7858e5e63a0eb8a5303\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/0d/8a/0729d2e6e3ca2a898ba55201f905da7db3f838a33df5b3fcdd\n",
            "Successfully built lightfm\n",
            "Installing collected packages: lightfm\n",
            "Successfully installed lightfm-1.17\n"
          ]
        }
      ],
      "source": [
        "%pip install lightfm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "id": "rxUgDm3-D3L6",
        "outputId": "c386ce92-da1d-488f-c373-6f27350404b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.1.0 scikit-optimize-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas-profiling"
      ],
      "metadata": {
        "id": "RQ2NrzSeECIh",
        "outputId": "ad50a88c-b8dd-4f5e-b78d-a18f7cb10a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas-profiling\n",
            "  Downloading pandas_profiling-3.2.0-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting joblib~=1.1.0 (from pandas-profiling)\n",
            "  Downloading joblib-1.1.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pandas-profiling) (1.13.1)\n",
            "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in /usr/local/lib/python3.11/dist-packages (from pandas-profiling) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from pandas-profiling) (3.10.0)\n",
            "Requirement already satisfied: pydantic>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from pandas-profiling) (2.10.6)\n",
            "Requirement already satisfied: PyYAML>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from pandas-profiling) (6.0.2)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.11/dist-packages (from pandas-profiling) (3.1.5)\n",
            "Collecting markupsafe~=2.1.1 (from pandas-profiling)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting visions==0.7.4 (from visions[type_image_path]==0.7.4->pandas-profiling)\n",
            "  Downloading visions-0.7.4-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pandas-profiling) (1.26.4)\n",
            "Collecting htmlmin>=0.1.12 (from pandas-profiling)\n",
            "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pandas-profiling) (0.5.2)\n",
            "Collecting phik>=0.11.1 (from pandas-profiling)\n",
            "  Downloading phik-0.12.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting tangled-up-in-unicode==0.2.0 (from pandas-profiling)\n",
            "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.11/dist-packages (from pandas-profiling) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.11/dist-packages (from pandas-profiling) (4.67.1)\n",
            "Requirement already satisfied: seaborn>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from pandas-profiling) (0.13.2)\n",
            "Collecting multimethod>=1.4 (from pandas-profiling)\n",
            "  Downloading multimethod-2.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.11/dist-packages (from visions==0.7.4->visions[type_image_path]==0.7.4->pandas-profiling) (25.1.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.11/dist-packages (from visions==0.7.4->visions[type_image_path]==0.7.4->pandas-profiling) (3.4.2)\n",
            "Collecting imagehash (from visions[type_image_path]==0.7.4->pandas-profiling)\n",
            "  Downloading ImageHash-4.3.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling) (11.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.0->pandas-profiling) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.0->pandas-profiling) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.0->pandas-profiling) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.0->pandas-profiling) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.0->pandas-profiling) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.0->pandas-profiling) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.0->pandas-profiling) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas-profiling) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas-profiling) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.8.1->pandas-profiling) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.8.1->pandas-profiling) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.8.1->pandas-profiling) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->pandas-profiling) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->pandas-profiling) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->pandas-profiling) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->pandas-profiling) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.0->pandas-profiling) (1.17.0)\n",
            "Collecting PyWavelets (from imagehash->visions[type_image_path]==0.7.4->pandas-profiling)\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Downloading pandas_profiling-3.2.0-py2.py3-none-any.whl (262 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.6/262.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading visions-0.7.4-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/102.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.1.1-py2.py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.8/309.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading multimethod-2.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading phik-0.12.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (687 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m687.8/687.8 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ImageHash-4.3.2-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: htmlmin\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27081 sha256=81e11425985aa8e4ffa2e93e9df6ef46382e96073b1522d3f183be098c603466\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/55/1a/19cd535375ed1ede0c996405ebffe34b196d78e2d9545723a2\n",
            "Successfully built htmlmin\n",
            "Installing collected packages: htmlmin, tangled-up-in-unicode, PyWavelets, multimethod, markupsafe, joblib, imagehash, visions, phik, pandas-profiling\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.2\n",
            "    Uninstalling joblib-1.4.2:\n",
            "      Successfully uninstalled joblib-1.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-learn 1.6.1 requires joblib>=1.2.0, but you have joblib 1.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyWavelets-1.8.0 htmlmin-0.1.12 imagehash-4.3.2 joblib-1.1.1 markupsafe-2.1.5 multimethod-2.0 pandas-profiling-3.2.0 phik-0.12.4 tangled-up-in-unicode-0.2.0 visions-0.7.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "markupsafe"
                ]
              },
              "id": "b49e4f7167664b3e9026911bc15e1b2e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import display_html\n",
        "import warnings\n",
        "\n",
        "from matplotlib.gridspec import GridSpec\n",
        "%matplotlib inline\n",
        "\n",
        "from lightfm import LightFM\n",
        "from lightfm.evaluation import precision_at_k, auc_score, recall_at_k\n",
        "from lightfm.cross_validation import random_train_test_split\n",
        "from lightfm.data import Dataset\n",
        "from skopt import forest_minimize\n"
      ],
      "metadata": {
        "id": "_mhzs4Z_ELz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_side_by_side(*args):\n",
        "  html_str = ''\n",
        "  for df in args:\n",
        "    html_str += df.to_html()\n",
        "  display_html(html_str.replace(\n",
        "    'table', 'table style=\"display:inline\"'), raw=True)\n",
        "\n",
        "# update the working directory to the root of the project\n",
        "os.chdir('..')\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "UeGYrZxtFfGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path ='content/drive/MyDrive/Recommender_systems'"
      ],
      "metadata": {
        "id": "x0j2SGdMGx4w",
        "outputId": "b04af93d-d322-4b3b-820d-a28cd203c790",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "book_metadata = pd.read_json(path+'/goodreads_books_poetry.json', lines=True)\n",
        "interaction = pd.read_json(path+'/goodreads_interaction_poetry.json', lines=True)\n"
      ],
      "metadata": {
        "id": "Sh_CJO7ZV5Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_metadata.columns.values"
      ],
      "metadata": {
        "id": "TPU4iMitWlWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "array(['isbn', 'text_reviews_count', 'series', 'countru_code', 'language_code', ' popular_shelves', 'asin',  'is_ebook', 'average_rating', ' kindle_asin', 'similar_books', ' description', 'format', 'link',  'authors', 'publisher', 'num_pages', 'publication_day', 'isbn13', 'publication_month', 'edition_information', 'publication_year', 'url', 'image_url', 'book_id', 'ratings_count', 'work_id', title', title_without_series'], dtype=object)"
      ],
      "metadata": {
        "id": "3rD1NoPOHXXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "book_metadata.sample(2)"
      ],
      "metadata": {
        "id": "P87ambi0HHI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_metadata_selected = book_metadata[['book_id', 'average_rating', 'is_ebook', 'num_pages', 'publication_year', 'ratings_count', 'language_code']]\n",
        "books_metadata_selected.sample(5)"
      ],
      "metadata": {
        "id": "ntcA2juPJFmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas_profiling as pp\n",
        "\n",
        "# replace the blank cell with Nan\n",
        "book_metadata_selected.replace('', np.nan, inplace=True)\n",
        "\n",
        "# not taking book_id into profiler report\n",
        "profile = pp.ProfileReport(book_metadata_selected[['average_rating', 'is_ebook', 'num_pages', 'publication_year', 'ratings_count']])\n",
        "profile.to_file(output_file=path +'/result/profiler_books_metadata_1.html')"
      ],
      "metadata": {
        "id": "P1k6IorDHbty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile"
      ],
      "metadata": {
        "id": "YlVkywUvJtkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using pandas cut method to c onvert fields into discrete intervals\n",
        "books_metadata_selected['num_pages'].replace(np.nan, -1, inplace=True)\n",
        "books_metadata_selected['num_pages'] = pd.to_numeric(books_metadata_selected['num_pages'])\n",
        "books_metadata_selected['num_pages'] = pd.cut(books_metadata_selected['num_pages'], bins=25)\n",
        "\n",
        "# rounding ratings to neares .5 score\n",
        "books_metadata_selected['average_rating'] = books_metadata_selected['average_rating'].apply(lambda x: round(x * 2) / 2)\n",
        "\n",
        "# using pandas qcut method to convert  fields into quantile-based discrete intervals\n",
        "books_metadata_selected['ratings_count'] = pd.to_numeric(books_metadata_selected['ratings_count'])\n",
        "books_metadata_selected['ratings_count'] = pd.qcut(books_metadata_selected['ratings_count'], 25)\n",
        "\n",
        "# replacing missing values to year 2100\n",
        "books_metadata_selected['publication_year'].replace(np.nan, 2100, inplace=True)\n",
        "\n",
        "# replacing missing values to'unknoun'\n",
        "books_metadata_selected['language_code'].replace(np.nan, 'unknown', inplace=True)\n",
        "\n",
        "# convert is_ebook into 1/0 where true=1 and false=0\n",
        "books_metadata_selected['is_ebook'] = books_metadata_selected['is_ebook'].apply(lambda x: 1.0*(x == 'true')) # lambda x: 1 if x else 0"
      ],
      "metadata": {
        "id": "pvL2iXgwJvs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porofile = pandas_profiling.ProfileReport(books_metadata_selected[['average_rating', 'is_ebook', 'num_pages', 'publication_year', 'ratings_count']])\n",
        "profile.to_file(output_file=path +'/result/profiler_books_metadata_2.html')"
      ],
      "metadata": {
        "id": "xLtWTBYeESyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile"
      ],
      "metadata": {
        "id": "Xey3dbDKHqlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_metadata_selected.sample(5)"
      ],
      "metadata": {
        "id": "wuLN1wwrG_8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interaction.column.values"
      ],
      "metadata": {
        "id": "-1RfPHrYHDNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "array(['user_id', 'book_id', 'review_id', 'is_read', 'rating', 'review_text_incomplite', 'data_added', 'data_updated', 'read_at', 'started_at'], dtype=object)"
      ],
      "metadata": {
        "id": "yRlIUw-lH-FL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interaction.sample(5)"
      ],
      "metadata": {
        "id": "aYj77Y0DIkPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interaction.shape"
      ],
      "metadata": {
        "id": "hwkgx3V2IqYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# limit the books metadata to selected fields\n",
        "interactions_selected = interactions[['user_id', 'book_id', 'review_id', 'is_read', 'rating']]\n",
        "\n",
        "# mapping boolean to string\n",
        "booleanDictionary = {True: 'true', False: 'false'}\n",
        "interactions_selected['is_read'] = interaction_selected['is_read'].replace(booleanDictionary)\n",
        "\n",
        "interactions_selected.sample(5)"
      ],
      "metadata": {
        "id": "6Io0dx1JIt6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile = pandas_profiling.ProfileReport(interactions_selected[['is_read', 'rating']])\n",
        "profile.to_file(output_file=path +'/result/profiler_interactions.html')"
      ],
      "metadata": {
        "id": "4nVkiBliJyIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert is_read column into 1/0 where true=1 and false=0\n",
        "interactions_selected['is_read'] = interactions_selected['is_read'].apply(lambda x: 1.0*(x == 'true')) # lambda x: 1 if x else 0"
      ],
      "metadata": {
        "id": "yOhiU2XeKAdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions_selected.sample(10)"
      ],
      "metadata": {
        "id": "oqDOEffDKa6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions_selected.groupby(['rating', 'is_read']).size().reset_index().pivot(columns='rating', index='is_read', values=0)"
      ],
      "metadata": {
        "id": "Y6d2v3UpKhCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "interactions_selected = interactions_selected.loc[interactions_selected['is_read']==1, ['user_id', 'book_id', 'rating']]\n",
        "interactions_selected = interactions_selected[interactions_selected['user_id'].isin(random.sample(list(interactions_selected['user_id'].unique()), k=5000))]\n",
        "\n",
        "interactions_selected.sample(10)"
      ],
      "metadata": {
        "id": "3V4O0__-LGzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions_selected.shape"
      ],
      "metadata": {
        "id": "MPpwqVtEMHXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_dict = {}\n",
        "df = books_metadata[['books_id', 'title']].sort_values('book_id').reset_index()\n",
        "for i in range(df.shape[0]):\n",
        "  item_dict[(df.loc[i, 'book_id'])] = df.loc[i, 'title']"
      ],
      "metadata": {
        "id": "aU5zQm7tMmuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummify categorical features\n",
        "books_metadata_selected_transformed = pd.get_dummies(books_metadata_selected, columns=['average_rating', 'is_ebook', 'num_pages', 'publication_year', 'ratings_count', 'language_code'])\n",
        "books_metadata_selected_transformed = books_metadata_selected_transformed.sort_values('book_id').reset_index().drop('index', axis=1)\n",
        "books_metadata_selected_transformed.head(5)"
      ],
      "metadata": {
        "id": "mzEFXKsiM_N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to csr matrix\n",
        "books_metadata_csr = csr_matrix(books_metadata_selected_transformed.drop('book_id', axis=1).values)\n",
        "books_metadata_csr"
      ],
      "metadata": {
        "id": "x4eTGmz3N1Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_book_interaction = pd.pivot_table(interactions_selected, index='user_id', columns='book_id', values='rating')\n",
        "\n",
        "#fill missing values with 0\n",
        "user_book_interaction = user_book_interaction.fillna(0)\n",
        "user_book_interaction.head(10)"
      ],
      "metadata": {
        "id": "SksEGG-zOK4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = list(user_book_interaction.index)\n",
        "user_dict = {}\n",
        "counter = 0\n",
        "for i in user_id:\n",
        "  user_dict[i] = counter\n",
        "  counter += 1"
      ],
      "metadata": {
        "id": "ZBf0eKA2Opjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to csr matrix\n",
        "user_book_interaction_csr = csr_matrix(user_book_interaction.values)\n",
        "user_book_interaction_csr"
      ],
      "metadata": {
        "id": "kkzgByE7PMtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LightFM(loss='warp',\n",
        "                random_state=2016,\n",
        "                learning_rate=0.90,\n",
        "                no_components=150,\n",
        "                user_alpha=0.000005)\n",
        "\n",
        "model = model.fit(user_book_interaction_csr,\n",
        "                  epochs=100,\n",
        "                  num_threads=16, verbose=False)\n"
      ],
      "metadata": {
        "id": "X75s8CloPVoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_recomendation_user(model, interactions, user_id, user_dict, item_dict, threshold=0, nrec_items=5, show=True):\n",
        "\n",
        "  n_users, n_irtems = interactions.shape\n",
        "  user_x = user_dict[user_id]\n",
        "  scores = pd.Series(model.predict(user_x, np.arange(n_items), item_features=books_metadata_csr))\n",
        "  scores.index = interactions.columns\n",
        "  scores = list(pd.Series(scores.sort_values(ascending=False).index))\n",
        "\n",
        "  known_items = list(pd.Series(interactions.loc[user_id, :]\n",
        "                               [interactions.loc[user_id, :] > threshold].index)\n",
        "                               .sort_values(ascending=False))\n",
        "\n",
        "  scores = [x for x in scores if x not in known_items]\n",
        "  return_score_list = scores[0:nrec_items]\n",
        "  known_items = list(pd.Series(known_items).apply(lambda x: item_dict[x]))\n",
        "  scores = list(pd.Series(return_score_list).apply(lambda x: item_dict[x]))\n",
        "\n",
        "  if show == True:\n",
        "    print(\"User: \" + str(user_id))\n",
        "    print(\"Known Likes:\")\n",
        "    counter = 1\n",
        "    for i in known_items:\n",
        "      print(str(counter) + ': ' + i)\n",
        "      counter += 1\n",
        "\n",
        "    print(\"\\n Recommended Items:\")\n",
        "    counter = 1\n",
        "    for i in scores:\n",
        "      print(str(counter) + ': ' + i)\n",
        "      counter += 1\n",
        ""
      ],
      "metadata": {
        "id": "rTNycPKWP57D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_recomendation_user(model, user_book_interaction, 'ff52b7331f2ccab0582678644fed9d85', user_dict, item_dict)"
      ],
      "metadata": {
        "id": "EijeRgxy6PQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_recomendation_user(model, user_book_interaction, 'ff52g7331f2ccab0682678644fed9f85', user_dict, item_dict)"
      ],
      "metadata": {
        "id": "FsWdCn0m7Awb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (venv)",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}