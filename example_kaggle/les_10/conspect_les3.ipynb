{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiracencoSerghei/DataScienceHW/blob/main/example_kaggle/les_10/conspect_les3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZIkQ4FxB4_O"
      },
      "source": [
        "\n",
        "**Навчання з використанням передвиборної мережі​**\n",
        "\n",
        "\n",
        "\n",
        "Існує два основних підходи, які використовують попередньо навчені мережі:\n",
        "\n",
        "\n",
        "\n",
        "- Виділення ознак (feature extraction).\n",
        "- Донавчання (fine-tuning)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8kof78YB4_P"
      },
      "source": [
        "**Training with a Pretrained Network**\n",
        "\n",
        "There are two main approaches to using pretrained networks:\n",
        "\n",
        "- Feature Extraction\n",
        "\n",
        "- Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0COtjxQB4_Q"
      },
      "outputs": [],
      "source": [
        "# # Check active kernel\n",
        "# !jupyter kernelspec list\n",
        "\n",
        "# # Install IPython kernel for your venv\n",
        "# !pip install ipykernel\n",
        "# !python -m ipykernel install --user --name=.venv --display-name=\"Python (.venv)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zngAzXzB4_Q"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "conv_base = VGG16(weights=\"imagenet\", include_top=False, input_shape=(150, 150, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gyn4POMvB4_Q"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "conv_base = VGG16(weights=\"imagenet\", include_top=False, input_shape=(150, 150, 3))\n",
        "conv_base.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "   conv_base,\n",
        "   layers.Flatten(),\n",
        "   layers.Dense(256, activation=\"relu\"),\n",
        "   layers.Dense(1, activation=\"sigmoid\"),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=2e-5),\n",
        "    metrics=[\"acc\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8Aea-ZSB4_Q",
        "outputId": "5ea18fd0-08d5-4dd0-8f58-262946a3fa73"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m2,097,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,812,353</span> (64.13 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,812,353\u001b[0m (64.13 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,665</span> (8.00 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,097,665\u001b[0m (8.00 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58GKEbm9B4_R"
      },
      "outputs": [],
      "source": [
        "# train_dir = './dataset/train'\n",
        "# validation_dir ='./dataset/validation'\n",
        "\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#     rescale=1./255,\n",
        "#     rotation_range=40,\n",
        "#     width_shift_range=0.2,\n",
        "#     height_shift_range=0.2,\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True,\n",
        "#     fill_mode=\"nearest\"\n",
        "# )\n",
        "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# train_generator = train_datagen.flow_from_directory(\n",
        "#     train_dir,\n",
        "#     target_size=(150, 150),\n",
        "#     batch_size=20,\n",
        "#     class_mode=\"binary\"\n",
        "# )\n",
        "\n",
        "# validation_generator = test_datagen.flow_from_directory(\n",
        "#     validation_dir,\n",
        "#     target_size=(150, 150),\n",
        "#     batch_size=20,\n",
        "#     class_mode=\"binary\"\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V09B8RVCB4_R"
      },
      "outputs": [],
      "source": [
        "# from PIL import Image\n",
        "# img = Image.open('./dataset/test/cats/cat.1500.jpg')\n",
        "# img.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyW_1EHfB4_R",
        "outputId": "a8365de6-6153-4f13-c24d-0c988eb1485f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11.1.0\n"
          ]
        }
      ],
      "source": [
        "import PIL\n",
        "print(PIL.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mko6ldnrB4_R"
      },
      "outputs": [],
      "source": [
        "# history = model.fit(\n",
        "#     train_generator,\n",
        "#     steps_per_epoch=100,\n",
        "#     epochs=100,\n",
        "#     validation_data=validation_generator,\n",
        "#     validation_steps=50\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KFPtKHcB4_R"
      },
      "source": [
        "Проаналізуємо графіки зміни точності та втрат на тестових та валідаційних даних:\n",
        "\n",
        "Let's analyze the graphs of changes in accuracy and losses on test and validation data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJSTkCwMB4_R"
      },
      "source": [
        "Навчання настільки великої мережі займає багато часу, тому є сенс зберегти її:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkZ5lrjwB4_S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "model_path = os.path.join(current_dir, \"vgg16_based_model.hdf5\")\n",
        "\n",
        "# model.save(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZeamsVDB4_S",
        "outputId": "bd08f2e0-89b0-463e-e295-7719d3b72509"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Модель успішно завантажено!\n"
          ]
        }
      ],
      "source": [
        "model = load_model(model_path)\n",
        "print(\"Модель успішно завантажено!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGhbkdcRB4_S",
        "outputId": "2382bb11-8e37-4ad6-aa07-950b235d4422"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "Результат передбачення: [[0.99843115]]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Приклад: завантаження зображення\n",
        "img_path = \"./dataset/validation/dogs/dog.1002.jpg\"\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)  # додати batch dimension\n",
        "img_array = img_array / 255.0  # нормалізація (якщо потрібно)\n",
        "\n",
        "# Передбачення\n",
        "predictions = model.predict(img_array)\n",
        "print(\"Результат передбачення:\", predictions)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (.venv)",
      "language": "python",
      "name": ".venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}